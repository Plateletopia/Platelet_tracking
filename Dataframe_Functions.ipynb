{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulations of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def led_bins(dfg):\n",
    "    zgroup_names=np.arange(-6,70,4)\n",
    "    tbins=np.arange(0,196,2)\n",
    "    if 'zs' in dfg.columns:\n",
    "        zbins=np.arange(-8,72,4)\n",
    "        dfg['zled'] = pd.cut(dfg['zs'], zbins, labels=zgroup_names).astype('Int64')\n",
    "    if 'time' in dfg.columns:\n",
    "        dfg['tled'] = pd.cut(dfg['frame'], tbins, labels=tgroup_names).astype('Int64')\n",
    "    #if 'dist_c' in dfg.columns: \n",
    "     #   d\n",
    "     #   \n",
    "    #dfg['zled'] = pd.cut(dfg['zs'], zbins, labels=zgroup_names).astype('Int64') #210927:changed from 'zf'\n",
    "    \n",
    "    return dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_vars(df):\n",
    "#---------------------------------------------------------------------------\n",
    "#Some general variables\n",
    "    \n",
    "    df['time']=df['frame']*3.1\n",
    "    df.loc[:,'minute'] = pd.cut(df['time'], 10, labels=list(range(1,11,1)))\n",
    "    df=df.rename(columns={'xs':'x_s'})\n",
    "    track_thr=2\n",
    "    df.loc[:,'tracked']=df.nrtracks>track_thr\n",
    "    df['dist_c']=((df.loc[:,'x_s'])**2+(df.loc[:,'ys'])**2)**0.5\n",
    "    df['dist_cz']=((df.loc[:,'x_s'])**2+(df.loc[:,'ys'])**2+(df.loc[:,'zs'])**2)**0.5\n",
    "    #df['id']=df['exp_id'].astype('int').astype('str')+'-'+df['particle'].astype('str')\n",
    "    \n",
    "    return df\n",
    "#---------------------------------------------------------------------------\n",
    "def vars_expid(df):\n",
    "# exp_id and inh_exp_id \n",
    "\n",
    "    for c,path in enumerate(pd.unique(df.path)):\n",
    "        df.loc[(df.path==path),'exp_id']=c\n",
    "#\n",
    "    for x in pd.unique(df.inh): \n",
    "        num_exp_id=[]\n",
    "        num_inh_exp_id=[]\n",
    "        for n,y in enumerate (pd.unique(df[df.inh==x].exp_id),1):\n",
    "            df.loc[(df.inh==x)&(df.exp_id==y),'inh_exp_id']=n\n",
    "            num_exp_id.append(y)\n",
    "            num_inh_exp_id.append(n)\n",
    "        print(f'Treatment\\t\\t{x}\\nNo of experiments\\t{len(num_exp_id)}\\nexp_id\\t\\t\\t{num_exp_id}\\ninh_exp_id\\t\\t{num_inh_exp_id}\\n\\n')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_objs(df, search_range=3, memory=1):\n",
    "    #tracked_df = tp.link_df(df, search_range, pos_columns=['xs', 'ys', 'zs'], memory=memory)\n",
    "\n",
    "    df_tracks = []\n",
    "\n",
    "    for i, grp in tracked_df.groupby(['particle']):\n",
    "        grp=grp.sort_values('frame')\n",
    "        dvx = np.append(np.diff(grp['xs']), np.nan)\n",
    "        dvy = np.append(np.diff(grp['ys']), np.nan)\n",
    "        dvz = np.append(np.diff(grp['zs']), np.nan)\n",
    "        df_track=grp.pid.to_frame()\n",
    "        #df_track['particle']=grp.particle\n",
    "        df_track['nrtracks']=len(df_track)\n",
    "        df_track['dvx']=dvx\n",
    "        df_track['dvy']=dvy\n",
    "        df_track['dvz']=dvz\n",
    "        df_track['dv']=(df_track.dvx**2+df_track.dvy**2+df_track.dvz**2)**0.5\n",
    "        df_tracks.append(df_track)\n",
    "\n",
    "    df_tracks=pd.concat(df_tracks, axis=0)\n",
    "    df_tracks=df_tracks.sort_values('pid')\n",
    "    tracked_df = tracked_df.sort_values('pid')\n",
    "    tracked_df = pd.concat([tracked_df, df_tracks[['nrtracks', 'dvx', 'dvy', 'dvz', 'dv']]], axis=1)\n",
    "    return tracked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "\n",
    "def vars_pos(df):\n",
    "    #Skapar variabeln position som anger om trombocyten befinner sig i svansen eller huvudet\n",
    "    position=['head','tail','outside']\n",
    "    df['position']='outside'\n",
    "    df.loc[(df.dist_c<38),'position']='head'\n",
    "    df.loc[(df.dist_c>38)&(df.ys<0)&(abs(df.x_s)<38),'position']='tail'\n",
    "\n",
    "    #Create variable which specifies if the platelet is inside or outside the laser injury zone\n",
    "    df['inside_injury']=df.position.isin(['head'])\n",
    "    #pc.loc[:,'pos_injury']='outside'\n",
    "    #pc.loc[(pc.position=='head'),'bin_position']='inside'\n",
    "\n",
    "    #sns.countplot(x='position',data=pc)\n",
    "    print('Value counts Position\\n',pc.position.value_counts(),'Value counts inside injury',df.inside_injury.value_counts())\n",
    "    df.loc[:,'height']=pd.cut(df.zf, 3, labels=[\"bottom\", \"middle\", \"top\"])\n",
    "    df.loc[:,'z_pos']=pd.cut(df.zf, 2, labels=[\"bottom\", \"top\"])\n",
    "    \n",
    "    df['zz']=np.round(df.loc[:,'zf'],decimals=0)#pc['zz']=np.round(pc.loc[:,'zs'],decimals=0)\n",
    "    df = df.astype({'zz': int})\n",
    "    zbins=np.arange(-8,72,4)\n",
    "    zgroup_names=np.arange(-6,70,4)\n",
    "    df['zled'] = pd.cut(df['zf'], zbins, labels=zgroup_names).astype('Int64')\n",
    "    return df\n",
    "\n",
    "\n",
    "#pc=pc.drop(columns='path')\n",
    "    #return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "def vars_mov(df):\n",
    "#Movement classification\n",
    "    df.loc[:,'dvz_s']=df.dvz*1000/3.1\n",
    "    df.loc[:,'cont_s']=df.loc[:,'cont']*1000/3.1\n",
    "#Add categorical variable to describe platelet movement patterns\n",
    "    #df.loc[:,'mov_class']='none'\n",
    "    df.assign()\n",
    "\n",
    "    for exp_id in pd.unique(df.exp_id):\n",
    "        dfi=df[df.exp_id==exp_id].copy()\n",
    "    \n",
    "    #contractile=pd.unique(dfi[(dfi.cont_tot>5)&((dfi.cont_tot/dfi.displ_tot)>0.5)].particle)\n",
    "    #New deifinition 191209\n",
    "        try:\n",
    "            still=pd.unique(dfi[((dfi.displ_tot/dfi.nrtracks)<0.1)&(dfi.displ_tot<4)].particle)\n",
    "            loose=pd.unique(dfi[(dfi.displ_tot>5)&((dfi.cont_tot/dfi.displ_tot)<0.2)].particle)\n",
    "            contractile=pd.unique(dfi[((dfi.cont_tot/dfi.displ_tot)>0.5)&(dfi.displ_tot>1)].particle)\n",
    "        except TypeError:\n",
    "            print(exp_id,dfi.displ_tot.dtypes,dfi.nrtracks.dtypes,(dfi.displ_tot/dfi.nrtracks))\n",
    "    \n",
    "        df.loc[(df.exp_id==exp_id)&(df['particle'].isin(still)),'mov_class']=\"still\"\n",
    "        df.loc[(df.exp_id==exp_id)&(df['particle'].isin(loose)),'mov_class']=\"loose\"\n",
    "        df.loc[(df.exp_id==exp_id)&(df['particle'].isin(contractile)),'mov_class']=\"contractile\"\n",
    "\n",
    "\n",
    "#Skapar variabeln movement som anger om trombocyterna for ogonblicket ror sig kontraktilt, driftar eller star stilla\n",
    "    df['movement']='none'\n",
    "    df.loc[(df.dv<0.1) & (df.tracked),'movement']='immobile' #pc.loc[(pc.dv)<0.3,'movement']='still'\n",
    "    df.loc[(abs(df.dvy/df.dv)>0.5) & (df.dvy<0),'movement']='drifting' #pc.loc[(pc.dv>0.3)&(pc.cont_p<0.5),'movement']='drifting'\n",
    "    df.loc[(df.dv>0.3) & (df.cont_p>0.5) ,'movement']='contracting'\n",
    "    df.loc[(pc.stab>3),'movement']='unstable'\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_labels(dfg,binned_var,bins):\n",
    "    dfg[binned_var]=pd.cut(dfg[binned_var],bins,precision=0)\n",
    "    bin_var=f'{binned_var}_binlabel'\n",
    "    bin_labels=[]\n",
    "    for bin in dfg[binned_var].sort_values().unique():\n",
    "        bin_label=str(np.round(np.mean((bin.right+bin.left)/2),0))\n",
    "        bin_labels.append(bin_label)\n",
    "        #print (bin,bin_label)\n",
    "        dfg.loc[dfg[binned_var]==bin,bin_var]=bin_label\n",
    "    bin_order = sorted(bin_labels, key=lambda x: float(x))\n",
    "    return dfg,bin_var,bin_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qbinning_labels(dfg,binned_var,bins):\n",
    "    dfg[binned_var]=pd.qcut(dfg[binned_var],bins,precision=0)\n",
    "    bin_var=f'{binned_var}_binlabel'\n",
    "    bin_labels=[]\n",
    "    for bin in dfg[binned_var].sort_values().unique():\n",
    "        bin_label=str(int(np.round(np.mean((bin.right+bin.left)/2),0)))\n",
    "        bin_labels.append(bin_label)\n",
    "        #print (bin,bin_label)\n",
    "        dfg.loc[dfg[binned_var]==bin,bin_var]=bin_label\n",
    "    bin_order = sorted(bin_labels, key=lambda x: float(x))\n",
    "    return dfg,bin_var,bin_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qbinning_labels1(dfg,binned_var,bins):\n",
    "    dfg[binned_var]=pd.qcut(dfg[binned_var],bins,precision=0)\n",
    "    bin_var=f'{binned_var}_binlabel'\n",
    "    #bin_labels=[]\n",
    "    for bin in dfg[binned_var].sort_values().unique():\n",
    "        bin_label=int(np.round(np.mean((bin.right+bin.left)/2),0))\n",
    "        #bin_labels.append(bin_label)\n",
    "        #print (bin,bin_label)\n",
    "        dfg.loc[dfg[binned_var]==bin,bin_var]=bin_label\n",
    "    #bin_order = sorted(bin_labels, key=lambda x: float(x))\n",
    "    return dfg,bin_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedir(results_folder):\n",
    "    try:\n",
    "        os.mkdir(results_folder)\n",
    "    \n",
    "    except FileExistsError: \n",
    "        print(f'Folder {results_folder} already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu_var_choice():\n",
    "    from IPython.display import clear_output    \n",
    "#---------------------------------------------------------------------------------------------        \n",
    "    def print_menu(dic_columns):       # Your menu design here\n",
    "        #print(5 * \"\\n\")\n",
    "        print(73 * \"-\")\n",
    "        print(\"Choose packages you don't need in dataframe\")\n",
    "        #print(73 * \"-\")\n",
    "        print(\"1. Nearest neighbours: \",dic_columns[1])\n",
    "        #print(73 * \"-\")\n",
    "        print(\"2. Average dist nearest neighbours: \",dic_columns[2])\n",
    "        #print(73 * \"-\")\n",
    "        print(\"3. DBSCAN: \",dic_columns[3])\n",
    "        #print(73 * \"-\")\n",
    "        print(\"4. xtra tracking: \",dic_columns[4])\n",
    "        #print(73 * \"-\")\n",
    "        print(\"5. Platelet shape measures: \", dic_columns[5])\n",
    "        #print(73 * \"-\")\n",
    "        print(\"6. Fluorescence of plt marker c2: \", dic_columns[6])\n",
    "        #print(73 * \"-\")\n",
    "        print(\"7. Plt movement patterns: \", dic_columns[7])\n",
    "        #print(73 * \"-\")\n",
    "        print(\"8. Xtra plt position variables: \", dic_columns[8])\n",
    "        #print(73 * \"-\")\n",
    "        print(\"9. Scaled movements: \", dic_columns[8])\n",
    "        \n",
    "#--------------------------------------------------------------------------------------------- \n",
    "\n",
    "    def choices(columns,n_df,a,dic_columns):\n",
    "       \n",
    "                    \n",
    "        #columns=pc.columns\n",
    "        #if n_df==0:\n",
    "         \n",
    "        del_list=[]#del_list=[]\n",
    "        not_in_df_=[]\n",
    "        \n",
    "        for n,package in dic_columns.items():\n",
    "            if n in a:\n",
    "                for col in package:\n",
    "                    if col in columns:\n",
    "                        del_list.append(col)\n",
    "                    else:\n",
    "                        not_in_df_.append(col)\n",
    "                        #pc=pc.drop([col],axis=1)\n",
    "                        \n",
    "                        #pc=pc.drop([col],axis=1)\n",
    "        #else:\n",
    "        #        input(\"Wrong input. Enter any key to try again..\")\n",
    "        \n",
    "        \n",
    "        return del_list,not_in_df_\n",
    "#--------------------------------------------------------------------------------------------- \n",
    "    dic_columns={0:['treatment','index'],\n",
    "                     1:['nb_i_0','nb_i_1','nb_i_2','nb_d_0','nb_d_1','nb_d_2'],\n",
    "                     2:['nba_d_5','nba_d_10','nba_d_15'],\n",
    "                     3:['cl_idx_5','cl_idx_7.5','cl_idx_10','cl_idx_15','cl_idx_20','cld'],\n",
    "                     4:['cont_tot','displ_tot','dvz_tot','dvy_tot'],\n",
    "                     5:['elong', 'flatness','treatment', 'cohort', 'eigval_0', 'eigval_1', 'eigval_2'],\n",
    "                     6:['c2_mean', 'c2_max'],\n",
    "                    7:['mov_class', 'movement'],\n",
    "                    8:['position','inside_injury', 'height', 'z_pos', 'zz', 'zled'],\n",
    "                    9:['dvz_s','cont_s']}\n",
    "    #global exp_series,inh_order,inh_labels\n",
    "    \n",
    "    #print(\"These dataframes are available in your directory\")\n",
    "    \n",
    "    df_=[]\n",
    "    arr_txt = [x for x in os.listdir() if x.endswith(\"dataframe\")]\n",
    "    for c, value in enumerate(arr_txt,0):\n",
    "        print(c, value) \n",
    "    col_vars=input(\"Choose the dataframes you want to use separeted by spaces from the list below:\")\n",
    "    #print(\"Enter your choice as integers separeted by spaces: \")\n",
    "    flist = [int(x) for x in col_vars.split()]\n",
    "    \n",
    "    clear_output(wait=False)    \n",
    "    print_menu(dic_columns)    # Displays menu\n",
    "        #choice = input(\"Enter your choice as a list of integers: \")\n",
    "    \n",
    "    a = [int(x) for x in input(\"Enter your choice as integers separeted by spaces: \").split()]\n",
    "    \n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    for n_df,fi in enumerate(flist):\n",
    "        pc=pd.read_pickle(arr_txt[fi])\n",
    "        if n_df==0:\n",
    "            #print(\"These Columns are present in your dataframes\")\n",
    "            columns=pc.columns\n",
    "            #print(columns)\n",
    "        del_list,not_in_df_=choices(columns,n_df,a,dic_columns)\n",
    "        pc=pc.drop(del_list,axis=1)\n",
    "        print(arr_txt[fi])\n",
    "        print(f'Columns deleted: {del_list}',\n",
    "              f'\\nColumns not in original dataframe: {not_in_df_}')\n",
    "        clear_output(wait=True)\n",
    "        #print(f'Columns not in original dataframe: {not_in_df_}')\n",
    "        df_.append(pc)        \n",
    "    pc=pd.concat(df_, ignore_index=True,names='pid').reset_index()\n",
    "    pc.index.name = 'pid'\n",
    "    \n",
    "    #clear_output(wait=False)\n",
    "    choice = input('Do you only want to analyze tracked plts? (y/n)')\n",
    "    if choice =='y':\n",
    "        print('Set tracking threshold as integer')\n",
    "        thr_tr=int(input())\n",
    "        pc=pc[pc.nrtracks>thr_tr]\n",
    "    #clear_output(wait=False)\n",
    "    print(f'RESULTING DATAFRAME\\nNo of columns: {pc.shape[1]} \\nNo of rows: {pc.shape[0]}',\n",
    "          f'\\nMemory use: {np.round(sys.getsizeof(pc)/1000000,1)} Mb')\n",
    "    \n",
    "    return pc#del_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_menu_choice():\n",
    "    def print_menu():       # Your menu design here\n",
    "        print(30 * \"-\", \"Choose experimental cohort to run\", 30 * \"-\")\n",
    "        print(\"1. Inhibitor cohort \")\n",
    "        print(\"2. PAR4 cohort \")\n",
    "        print(\"3. Thrombin cohort \")\n",
    "        print(\"4. Custom cohort\")        \n",
    "        print(\"5. Exit from the script \")\n",
    "        print(73 * \"-\")\n",
    "    \n",
    "    global exp_series,inh_order,inh_labels\n",
    "    loop = True\n",
    "    int_choice = -1\n",
    "\n",
    "    while loop:          # While loop which will keep going until loop = False\n",
    "        print_menu()    # Displays menu\n",
    "        choice = input(\"Enter your choice [1-4]: \")\n",
    "\n",
    "        if choice == '1':\n",
    "            exp_series = 'Inhibitor cohort'\n",
    "            inh_order=['saline','dmso','biva','sq','cang']\n",
    "            inh_labels=['Saline','DMSO','Bivalirudin','Sq','Cangrelor']\n",
    "\n",
    "            loop = False\n",
    "        elif choice == '2':\n",
    "            exp_series = 'PAR4 cohort'\n",
    "            inh_order=['ctrl','par4+-','par4-+','par4--']\n",
    "            inh_labels=['Control','PAR4 +/-','PAR4 -/+','PAR4-/-']\n",
    "            loop = False\n",
    "        elif choice == '3':\n",
    "            exp_series = 'Thrombin cohort'\n",
    "            inh_order=['saline','biva','par4--','par4--biva']\n",
    "            inh_labels=['Saline','Bivalirudin','PAR4 -/-','PAR4 -/- + Bivalirudin']\n",
    "            loop = False\n",
    "        elif choice == '4':\n",
    "            choice = ''\n",
    "            while len(choice) == 0:\n",
    "                exp_series = input(\"Enter a single filename of a conf file: \")\n",
    "            loop = False\n",
    "        elif choice == '5':\n",
    "            int_choice = -1\n",
    "            print(\"Exiting..\")\n",
    "            loop = False  # This will make the while loop to end\n",
    "        else:\n",
    "            # Any inputs other than values 1-4 we print an error message\n",
    "            input(\"Wrong menu selection. Enter any key to try again..\")\n",
    "    create_params()\n",
    "   # return [int_choice, choice]\n",
    "\n",
    "#Inhibitor orders for graphs \n",
    "#-------------------------------------------------------\n",
    "#inh_order1=['ctrl','biva','par4--','cang','par4--biva']\n",
    "#inh_order=['ctrl','saline','biva','par4--','cang','par4--biva']\n",
    "#inh_order1=['saline','biva','par4--','cang','par4--biva']\n",
    "#inh_order_thrombin=['saline','biva','par4--','par4--biva']\n",
    "\n",
    "#inh_order2=['saline','dmso','biva','sq','cang']\n",
    "#Inhibitor labels for graphs \n",
    "#-------------------------------------------------------\n",
    "#inh_labels=['Control','Saline','Bivalirudin','PAR4-/-','Cangrelor','PAR4-/- + Bivalirudin']\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_col_dics():\n",
    "    print(f'Categories of columns in dataframe for selection:\\n{73 * \"-\"}')\n",
    "#col_index=[0]\n",
    "    dic_list=[]\n",
    "    dic_names=[]\n",
    "    for nr,(key,c_list) in enumerate(dic_df_cols.items()):\n",
    "        print(f'{key}\\n{73 * \"-\"}')\n",
    "    #i_col,col_list = [ic for i,c in enumerate(c_list)]\n",
    "    #print(i_col,col_list)\n",
    "    #i_list,col_list=[],[]\n",
    "        #dic_name='dic_'+key\n",
    "        #print(dic_name)\n",
    "        key=dict()\n",
    "        for i_col,col in enumerate(c_list):\n",
    "            key[i_col]=col\n",
    "        print(key)\n",
    "        dic_list.append(key)\n",
    "        dic_names.append(dic_name)\n",
    "        #dic_name=key\n",
    "        #i_list.append(i_col)\n",
    "        #col_list.append(col)\n",
    "    #print(i_list,col_list)\n",
    "        print(f'{73 * \"-\"}')\n",
    "    #return(dic_list,dic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_col_dics():\n",
    "    print(f'Categories of columns in dataframe for selection:\\n{73 * \"-\"}\\t')\n",
    "#col_index=[0]\n",
    "    dic_list=[]\n",
    "    dic_names=[]\n",
    "    for nr,(key,c_list) in enumerate(dic_df_cols.items()):\n",
    "        print(key)\n",
    "        print(f'{73 * \"-\"}')\n",
    "        print(f'{c_list}\\n{73 * \"-\"}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_lists(df_var_list):\n",
    "#for cat_names in dic_names:\n",
    "#for name,dic in zip(dic_names,dic_list):\n",
    "#    dic_names\n",
    "    from IPython.display import clear_output    \n",
    "    clear_output(wait=False)\n",
    "\n",
    "    df_=[]\n",
    "    #df_cols=['pid', 'path', 'inh',]\n",
    "    df_cols=[]\n",
    "    col_list = [item for sublist in df_var_list for item in sublist]\n",
    "    #print(col_list)\n",
    "    #print(col_list,col_dict,'******')\n",
    "    #print(col_dict[col_list[0]])\n",
    " \n",
    "    p = Path('./Dataframes').glob('**/*')\n",
    "    paths = [x for x in p if x.is_file()]\n",
    "    list1=[path for inh in inh_order for path in paths if inh in path.name]\n",
    "    path_list=list(set(list1))\n",
    "    \n",
    "    for n_df,fi in enumerate(path_list):\n",
    "        dfi=pd.read_pickle(fi)\n",
    "        dfi_col=['path', 'inh','particle']\n",
    "        for col in col_list:\n",
    "            if col in dfi.columns:\n",
    "                dfi_col.append(col)      \n",
    "        df_.append(dfi.loc[:,dfi_col])\n",
    "    pc=pd.concat(df_, ignore_index=True).reset_index()#,names='pid'     \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'minute' in pc.columns:\n",
    "        pc.loc[:,'minute'] = pd.cut(pc['time'], 10, labels=np.arange(1,11,1))\n",
    "    if 'nrtracks' in pc:    \n",
    "        pc=nrtracks_menu(pc)\n",
    "    \n",
    "    \n",
    "    pc=new_exp_ids(pc)\n",
    "    pc=outliers_menu(pc)\n",
    "    plot_menu()\n",
    "    \n",
    "    pc=pc.drop(['level_0','index'],axis=1).reset_index()\n",
    "    pc.index.name = 'pid'\n",
    "    #pc.inh_exp_id.unique()\n",
    "    \n",
    "    #clear_output(wait=False)\n",
    "    print(f'Treatments = {pc.inh.unique()}') #Paths included = {pc.path.unique()}\\n\n",
    "    print(f'RESULTING DATAFRAME\\nNo of columns: {pc.shape[1]} \\nNo of rows: {pc.shape[0]}',\n",
    "          f'\\nMemory use: {np.round(sys.getsizeof(pc)/1000000,1)} Mb')\n",
    "    \n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_exp_ids(pc):\n",
    "    pc[\"exp_id\"] = pc.groupby([\"path\"]).ngroup()\n",
    "    for inh in pc.inh.unique():\n",
    "        pc.loc[pc.inh==inh,'inh_exp_id']=pc[pc.inh==inh].groupby('path').ngroup()#grouper.group_info[0]\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrtracks_menu(pc):\n",
    "    choice = input('Do you only want to analyze tracked plts? (y/n)')\n",
    "    if choice =='y':\n",
    "        print('Set tracking threshold as integer')\n",
    "        thr_tr=int(input())\n",
    "        pc=pc[pc.nrtracks>thr_tr].reset_index()\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_menu(pc):\n",
    "    choice = input('Remove Outliers? (y/n)')\n",
    "    if choice =='y':\n",
    "        outliers=pd.read_csv('df_outliers')\n",
    "        pc=pc[~pc.path.isin(outliers.path)]\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_menu():\n",
    "    global save_figs,results_folder,plot_formats,save_inh_names\n",
    "    choice = input('Automatically save plots? (y/n)')\n",
    "    if choice =='y':\n",
    "        save_figs=True\n",
    "        results_folder = input('Write name of folder for plots')\n",
    "        makedir(results_folder)\n",
    "        \n",
    "        plot_formats = input('Choose file format for plots:\\nWrite \"p\" for .png, \"s\" for .svg or \"b\" for both')\n",
    "        \n",
    "        save_names = input('Use treatment names in filenames? (y/n)')\n",
    "        if choice =='y':\n",
    "            save_inh_names=True\n",
    "        else:\n",
    "            save_inh_names=False\n",
    "    \n",
    "    if choice =='n':\n",
    "        save_figs=False\n",
    "        save_inh_names=False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_lists1(df_var_list):\n",
    "#for cat_names in dic_names:\n",
    "#for name,dic in zip(dic_names,dic_list):\n",
    "#    dic_names\n",
    "    from IPython.display import clear_output    \n",
    "    clear_output(wait=False)\n",
    "\n",
    "    df_=[]\n",
    "    #df_cols=['pid', 'path', 'inh',]\n",
    "    df_cols=[]\n",
    "    col_list = [item for sublist in df_var_list for item in sublist]\n",
    "    #print(col_list)\n",
    "    #print(col_list,col_dict,'******')\n",
    "    #print(col_dict[col_list[0]])\n",
    " \n",
    "    arr_txt = [x for x in os.listdir() if x.endswith(\"dataframe\")]\n",
    "    for c, value in enumerate(arr_txt,0):\n",
    "        print(c, value) \n",
    "    col_vars=input(\"Choose the dataframes you want to use separated by spaces from the list below:\")\n",
    "    #print(\"Enter your choice as integers separeted by spaces: \")\n",
    "    flist = [int(x) for x in col_vars.split()]\n",
    "    \n",
    "    \n",
    "    #print(f'Including columns:{df_cols}')\n",
    "    #clear_output(wait=False)\n",
    "    for n_df,fi in enumerate(flist):\n",
    "        dfi=pd.read_pickle(arr_txt[fi])\n",
    "        dfi_col=['pid', 'inh','particle']\n",
    "        for col in col_list:\n",
    "            if col in dfi.columns:\n",
    "                dfi_col.append(col)      \n",
    "        df_.append(dfi.loc[:,dfi_col])\n",
    "    pc=pd.concat(df_, ignore_index=True,names='pid').reset_index()\n",
    "    pc.index.name = 'pid'\n",
    "    \n",
    "    if 'nrtracks' in pc:\n",
    "        choice = input('Do you only want to analyze tracked plts? (y/n)')\n",
    "        if choice =='y':\n",
    "            \n",
    "            \n",
    "            print('Set tracking threshold as integer')\n",
    "            thr_tr=int(input())\n",
    "            pc=pc[pc.nrtracks>thr_tr]\n",
    "    #clear_output(wait=False)\n",
    "    print(f'RESULTING DATAFRAME\\nNo of columns: {pc.shape[1]} \\nNo of rows: {pc.shape[0]}',\n",
    "          f'\\nMemory use: {np.round(sys.getsizeof(pc)/1000000,1)} Mb')\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df():\n",
    "    from IPython.display import clear_output    \n",
    "\n",
    "#--------------------------------------------------------------------------------------------- \n",
    "    dic_columns={'positions1':['x_s', 'ys', 'zs'],\n",
    "                 'positions2':['position','inside_injury', 'height'],\n",
    "                 'positions3':['depth', 'z_pos', 'zz', 'zled','zf','minute'],\n",
    "                 'dist_c':['dist_c', 'dist_cz'],\n",
    "                 'int_c0':['c0_mean', 'c0_max'],\n",
    "                 'int_c1':['c1_mean', 'c1_max'],\n",
    "                 \"int_c2\":['c2_mean', 'c2_max'],\n",
    "                 \"plt_shape\":['elong', 'flatness','treatment', 'cohort', 'eigval_0', 'eigval_1', 'eigval_2'],\n",
    "                 \"nearest neighbours\":['nb_i_0','nb_i_1','nb_i_2','nb_d_0','nb_d_1','nb_d_2'],\n",
    "                 'average dist nearest neighbours':['nba_d_5','nba_d_10','nba_d_15'],\n",
    "                 \"DBSCAN\":['cl_idx_5','cl_idx_7.5','cl_idx_10','cl_idx_15','cl_idx_20','cld'],\n",
    "                 \"xtra_tracking\":['cont_tot','displ_tot','dvz_tot',],#'dvy_tot'\n",
    "                 'mov_1':['dvx', 'dvy', 'dvz', 'dv','stab'],\n",
    "                 'mov_2':['mov_class', 'movement'],\n",
    "                 'mov_3':['cont', 'cont_p'],\n",
    "                 'mov_s':['dvz_s','cont_s'],\n",
    "                 'info':['inj', 'exp', 'date','mouse'] \n",
    "                         #'treatment', 'cohort', ]\n",
    "        \n",
    "                 \n",
    "    }\n",
    "    #global exp_series,inh_order,inh_labels\n",
    "    \n",
    "    #print(\"These dataframes are available in your directory\")\n",
    "    df_=[]\n",
    "    df_cols=[['pid', 'path', 'frame','time','inh','minute','nrtracks','tracknr']]\n",
    "    arr_txt = [x for x in os.listdir() if x.endswith(\"dataframe\")]\n",
    "    for c, value in enumerate(arr_txt,0):\n",
    "        print(c, value) \n",
    "    col_vars=input(\"Choose the dataframes you want to use separeted by spaces from the list below:\")\n",
    "    #print(\"Enter your choice as integers separeted by spaces: \")\n",
    "    flist = [int(x) for x in col_vars.split()]\n",
    "    \n",
    "    for n,(i,c_list) in enumerate(dic_columns.items()):\n",
    "        c=input(f'Include :{c_list}? (y/n)')\n",
    "        if c=='y':\n",
    "            df_cols.append(c_list)\n",
    "    #print(df_cols)\n",
    "    df_cols = [item for sublist in df_cols for item in sublist]\n",
    "    print(f'Including columns:{df_cols}')\n",
    "    #clear_output(wait=False)\n",
    "    for n_df,fi in enumerate(flist):\n",
    "        dfi=pd.read_pickle(arr_txt[fi])\n",
    "        df_.append(dfi.loc[:,df_cols])\n",
    "    pc=pd.concat(df_, ignore_index=True,names='pid').reset_index()\n",
    "    pc.index.name = 'pid'\n",
    "    \n",
    "    choice = input('Do you only want to analyze tracked plts? (y/n)')\n",
    "    if choice =='y':\n",
    "        print('Set tracking threshold as integer')\n",
    "        thr_tr=int(input())\n",
    "        pc=pc[pc.nrtracks>thr_tr]\n",
    "    #clear_output(wait=False)\n",
    "    print(f'RESULTING DATAFRAME\\nNo of columns: {pc.shape[1]} \\nNo of rows: {pc.shape[0]}',\n",
    "          f'\\nMemory use: {np.round(sys.getsizeof(pc)/1000000,1)} Mb')\n",
    "    \n",
    "    return pc#del_list\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
